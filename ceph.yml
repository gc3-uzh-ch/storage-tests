---
- hosts: ceph_mon:ceph_ods
  vars:
    # Generated with uuidgen
    fsid: 7705608d-cbef-477a-865d-f5ae4c03370a
    # Should be OSDs * 100 / replicas, rounded-up to the nearest power of 2.
    # In our case: 4*48*100/2 = 9600
    pg_num: 16384
    pgp_num: 16384
    replicas: 2
    libvirt_uuid: 1bdc5dc9-c116-43fa-8be5-17d1c870761d
    devices:
      - sdaa
      - sdab
      - sdac
      - sdad
      - sdae
      - sdaf
      - sdag
      - sdah
      - sdai
      - sdaj
      - sdak
      - sdal
      - sdam
      - sdan
      - sdao
      - sdap
      - sdaq
      - sdar
      - sdas
      - sdat
      - sdau
      - sdav
      - sdaw
      # - sdb
      # - sdc
      # - sdd
      # - sde
      # - sdf
      # - sdg
      # - sdh
      # - sdi
      # - sdj
      # - sdk
      # - sdl
      # - sdm
      # - sdn
      # - sdo
      # - sdp
      # - sdq
      # - sdr
      # - sds
      # - sdt
      # - sdu
      # - sdv
      # - sdw
      # - sdx
      # - sdy
      # - sdz

  tasks:
    # Configure basic packages
    - name: Check if `python-apt` package is installed
      action: shell apt-get install -y python-apt
      tags:
        - apt

    - name: fix for uzh ubuntu distribution not present
      apt_repository: repo="deb http://www.gc3.uzh.ch/packages/uzhonly/ubuntu trusty main" state=absent
      tags: 
        - apt

    - name: Ensure extra reposistories are present (Ubuntu)
      apt_repository: repo="deb http://archive.ubuntu.com/ubuntu {{ ansible_distribution_release }} universe multiverse" state=present
      tags:
        - apt

    - name: install base packages
      apt: name={{ item }} state=installed update_cache=yes
      with_items:
        - sysvinit-utils
        - software-properties-common
        - python-software-properties
        - python-pycurl
        - aptitude
      tags:
        - apt
    
    # Install packages needed by ceph
    - name: configure apt key for CEPH repository
      apt_key: url=https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc state=present
      tags:
        - apt

    - name: add CEPH apt public repository
      apt_repository: repo='deb http://ceph.com/debian/ trusty main' state=present
      tags:
        - apt

    - name: Install required package for apt_repository.
      apt: pkg={{ item }} state=present
      with_items:
        - ceph
        - xfsprogs
        - linux-image-extra-{{ ansible_kernel }}
      tags:
        - apt


    - file: dest=/etc/ceph state=directory
      tags:
        - ceph

    - file: dest=/var/run/ceph state=directory
      tags:
        - ceph

    - file: dest=/var/lib/ceph/mon/ceph-{{ ansible_hostname }} state=directory
      tags:
        - ceph


    - mount: name=/var/lib/ceph/mon/ceph-{{ ansible_hostname }} src=/dev/sdb1 fstype=xfs state=mounted
      tags:
        - ceph

    # - action: file dest=/var/lib/ceph/osd/ceph-{{ ansible_hostname }} state=directory
    #   tags:
    #     - ceph

    - name: configure ceph
      local_action: template src=ceph/templates/etc/ceph/ceph.conf.j2 dest=/tmp/ceph.conf
      tags:
        - ceph
        - conf

    - name: Copy the configuration file on all the machines
      copy: src=/tmp/ceph.conf dest=/etc/ceph/ceph.conf
      tags:
        - ceph
        - conf

    - name: save glance key
      shell: ceph auth get-or-create client.glance
      register: glance_key
      when: "ansible_hostname == groups['ceph_mon'][0]"
      tags:
        - conf
        - test

    - name: save cinder key
      shell: ceph auth get-or-create client.cinder
      register: cinder_key
      when: "ansible_hostname == groups['ceph_mon'][0]"
      tags:
        - conf
        - test

    - name: save cinder key
      shell: ceph auth get-key client.cinder
      register: cinder_bare_key
      when: "ansible_hostname == groups['ceph_mon'][0]"
      tags:
        - conf
        - test

    - name: set facts to store glance and cinder keys
      when: "ansible_hostname == groups['ceph_mon'][0]"
      set_fact: 
        cinder_key: "{{ cinder_key.stdout }}"
        cinder_bare_key: "{{ cinder_bare_key.stdout }}"
        glance_key: "{{ glance_key.stdout }}"
      tags:
        - conf
        - test

- hosts: ceph_cloud_controller
  vars:
    libvirt_uuid: 1bdc5dc9-c116-43fa-8be5-17d1c870761d

  tasks:
    # Install packages needed by ceph
    - name: configure apt key for CEPH repository
      apt_key: url=https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc state=present
      tags:
        - apt

    - name: fix for uzh ubuntu distribution not present
      apt_repository: repo="deb http://www.gc3.uzh.ch/packages/uzhonly/ubuntu trusty main" state=absent
      tags: 
        - apt

    - name: add CEPH apt public repository
      apt_repository: repo='deb http://ceph.com/debian/ trusty main' state=present
      tags:
        - apt

    - name: Install required package for apt_repository.
      apt: pkg={{ item }} state=present
      with_items:
        - python-ceph
        - ceph
        - qemu-utils
      tags:
        - apt
    # qemu-utils is needed in case we need to create a volume starting
    # from a qcow2 image, since it has to be converted to raw

    - name: Ensure cfengine is NOT running
      service: name=cfengine3 state=stopped

    - name: Configure glance
      ini_file: dest=/etc/glance/glance-api.conf
                section=DEFAULT
                option={{ item.name }}
                value={{ item.value }}
      with_items:
        - name: default_store
          value: rbd
        - name: rbd_store_user
          value: glance
        - name: rbd_store_pool
          value: glance
        - name: show_image_direct_url
          value: True
      notify: restart glance

    - name: Configure cinder
      ini_file: dest=/etc/cinder/cinder.conf
                section=DEFAULT
                option={{ item.name }}
                value={{ item.value }}
      with_items:
        - name: volume_driver
          value: cinder.volume.drivers.rbd.RBDDriver
        - name: rbd_pool
          value: cinder
        - name: rbd_ceph_conf
          value: /etc/ceph/ceph.conf
        - name: rbd_flatten_volume_from_snapshot
          value: false
        # - name: rbd_max_clone_depth
        #   value: 5g
        - name: lance_api_version
          value: 2
        - name: rbd_user
          value: cinder
        - name: rbd_secret_uuid
          value: "{{ libvirt_uuid }}"
      notify: restart cinder

    - name: ensure ceph keyring is owned by glance
      file: path=/etc/glance/glance-api.conf owner=glance group=glance

    - name: Copy the configuration file on all the machines
      copy: src=/tmp/ceph.conf dest=/etc/ceph/ceph.conf
      tags:
        - ceph
        - conf

    - name: Create glance keyring
      copy: dest=/etc/ceph/ceph.client.glance.keyring content="{{ hostvars[groups['ceph_mon'][0]]['glance_key'] }}\n"
      tags:
        - conf
        - test

    - name: Create cinder keyring
      copy: dest=/etc/ceph/ceph.client.cinder.keyring content="{{ hostvars[groups['ceph_mon'][0]]['cinder_key'] }}\n"
      tags:
        - conf
        - test

  handlers:
    - name: restart glance
      service: name=glance-api state=restarted

    - name: restart cinder
      service: name=cinder-volume state=restarted


- hosts: ceph_cloud_compute
  vars:
    libvirt_uuid: 1bdc5dc9-c116-43fa-8be5-17d1c870761d

  tasks:
    # Install packages needed by ceph
    - name: configure apt key for CEPH repository
      apt_key: url=https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc state=present
      tags:
        - apt

    - name: fix for uzh ubuntu distribution not present
      apt_repository: repo="deb http://www.gc3.uzh.ch/packages/uzhonly/ubuntu trusty main" state=absent
      tags: 
        - apt

    - name: add CEPH apt public repository
      apt_repository: repo='deb http://ceph.com/debian/ trusty main' state=present
      tags:
        - apt

    - name: Install required package for apt_repository.
      apt: pkg={{ item }} state=present
      with_items:
        - python-ceph
        - ceph
      tags:
        - apt

    - name: Ensure cfengine is NOT running
      service: name=cfengine3 state=stopped
  
    - name: Copy the configuration file on all the machines
      copy: src=/tmp/ceph.conf dest=/etc/ceph/ceph.conf
      tags:
        - ceph
        - conf

    - name: Add secret for libvirt
      template: src=templates/cinder-secret.xml.j2 dest=/etc/libvirt/qemu/cinder-secret.xml owner=root group=root mode=0400
      notify: update libvirt secret
      tags:
        - conf
        - test


    - name: Configure nova-compute
      ini_file: dest=/etc/nova/nova.conf
                section=DEFAULT
                option={{ item.name }}
                value={{ item.value }}
      with_items:
        - name: libvirt_images_type
          value: rbd
        - name: libvirt_images_rbd_pool
          value: cinder
        - name: libvirt_images_rbd_ceph_conf
          value: /etc/ceph/ceph.conf
        - name: rbd_user
          value: cinder
        - name: rbd_secret_uuid
          value: "{{ libvirt_uuid }}"
        - name: libvirt_inject_password
          value: false
        - name: libvirt_inject_key
          value: false
        - name: libvirt_inject_partition
          value: -2
      notify: restart nova-compute


    - name: Download patch for live migration
      get_url: url=https://launchpadlibrarian.net/173194970/ensure_added_feature_is_unique.patch
               dest=/root/ensure_added_feature_is_unique.patch
      tags:
        - nova
      
    - name: Apply patch for live migration
      shell: patch --dry-run -p 1 < /root/ensure_added_feature_is_unique.patch && patch -p 1 < /root/ensure_added_feature_is_unique.patch
             chdir=/usr/lib/python2.7/dist-packages
      ignore_errors: true
      notify: restart nova-compute
      tags:
        - nova

  handlers:
    - name: update libvirt secret
      shell: virsh secret-define /etc/libvirt/qemu/cinder-secret.xml && virsh secret-set-value --secret {{ libvirt_uuid }} --base64 "{{ hostvars[groups['ceph_mon'][0]]['cinder_bare_key'] }}"

    - name: restart nova-compute
      service: name=nova-compute state=restarted
